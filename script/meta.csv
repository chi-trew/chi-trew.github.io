,paper_id,authors,title,session_id,paper_order,session,type,paper_status
0,20,"Erika Puiutta, Larbi Abdenebaoui and Susanne Boll",The Importance of Trust and Acceptance in User-Centred XAI - Practical Implications for a Manufacturing Scenario,-1.0,-1.0,-1,Poster,True
1,46,"Navita Goyal, Connor Baumler, Tin Nguyen and Hal Daumé",The Impact of Explanations on Fairness in Human-AI Decision Making: Protected vs Proxy Features,1.0,0.0,Trust for Fairness and Ethics,Talk,True
2,7,"Gaole He, Lucie Kuiper and Ujwal Gadiraju",Dunning-Kruger Effect Can Hinder Appropriate Reliance on AI Systems,0.0,0.0,Modeling Human Trust,Talk,True
3,8,"Jakob Schoeffer, Maria De-Arteaga and Niklas Kuehl","Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making",1.0,1.0,Trust for Fairness and Ethics,Talk,True
4,13,"Zhuoran Lu, Dakuo Wang and Ming Yin",Does More Advice Help? The Effects of Second Opinions from Peers in AI-Assisted Decision Making,2.0,0.0,Trust-calibrating Interfaces,Talk,True
5,14,Nadine Schlicker and Markus Langer,Introducing the trustworthiness assessment model and its implications for research on trust in artificial intelligence,0.0,1.0,Modeling Human Trust,Talk,True
6,17,"Clélie Amiot, François Charoy and Jérôme Dinet",Chatbots as decision aids: investigating reliance in Human-Chatbot collaboration vs. Human-Human collaboration,0.0,2.0,Modeling Human Trust,Talk,True
7,18,Dinara Talypova and Philipp Wintersberger,Team At Your Service: Can Multiple Conversational Agents Increase Functional Specificity in Automated Driving?,2.0,1.0,Trust-calibrating Interfaces,Talk,True
8,34,"Brihi Joshi, Ziyi Liu, Sahana Ramnath, Aaron Chan, Zhewei Tong, Qifan Wang, Yejin Choi and Xiang Ren",Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales,2.0,2.0,Trust-calibrating Interfaces,Talk,True
9,37,Matthias Kraus,"Measuring, Predicting, and Leveraging Trust for Proactive Dialog in Human-AI Teams",0.0,3.0,Modeling Human Trust,Talk,True
10,6,Nicolas Scharowski and Sebastian A.C. Perrig,Distrust in (X)AI - Measurement Artifact or Distinct Construct?,-1.0,-1.0,-1,Poster,True
11,9,"Sunnie S. Y. Kim, Elizabeth Watkins, Olga Russakovsky, Ruth Fong and Andrés Monroy-Hernández","Humans, AI, and Context: Understanding End-Users’ Trust in a Real-World Computer Vision Application",-1.0,-1.0,-1,Poster,True
12,22,"Zelun Tony Zhang, Yuanting Liu and Andreas Butz",Designing AI for Appropriation Will Calibrate Trust,-1.0,-1.0,-1,Poster,True
13,23,"Beau Schelble, Subhasree Sengupta, Alyssa Williams and Nathan McNeese",Addressing Trust Repair for AI Ethicality: The Influence of Team Role and Violation Type,1.0,2.0,Trust for Fairness and Ethics,Talk,True
14,36,"Eyal Ginosar, Susanna Kraemer, Marion Koelle, Heiko Müller, Susanne Boll and Jessica Cauchard",Co-Design of Autonomous Drones for Interactions with Bystanders,-1.0,-1.0,-1,Poster,True
15,44,"Tariq Andersen, Stina Matthiesen and Emil Vogt Sørensen",Chronic Heart Patients Perspectives on 30-Day ML-based Predictions: Exploring Implications for Self-Care Practice and Patient-Physician Collaboration,-1.0,-1.0,-1,Poster,True
16,27,"Marissa Radensky, Julie Anne Séguin, Jang Soo Lim, Kristen Olson and Robert Geiger",I Think You Might Like This': Exploring Effects of Confidence Signal Patterns on Trust in and Reliance on Conversational Recommender Systems,2.0,3.0,Trust-calibrating Interfaces,Talk,True
17,29,"Retno Larasati, Anna De Liddo and Enrico Motta",Human and AI Trust: Trust Attitude Measurement Instrument Development,-1.0,-1.0,-1,Poster,True
18,30,"Steven R. Gomez, Kevin K. Nam, Kimberlee Chestnut Chang, Gregg Marcus and Erin K. Chiou",Human-AI Trust Calibration Should Be Contextual and Continuous,-1.0,-1.0,-1,Poster,True
19,39,Rachel Ringe and Robert Porzel,A Task-based Metric for Measuring Trust in Autonomous Robots for Everyday Activities,-1.0,-1.0,-1,Poster,True
20,31,Ian Thomas and Danielle Szafir,Evaluating User Trust in Active Learning Systems Through Query Policy and Uncertainty Visualization,-1.0,-1.0,-1,Poster,True
21,35,"Shiye Cao, Shichang Ke, Yanyan Mo, Anqi Liu and Chien-Ming Huang",Eyes Are the Windows to AI Reliance: Towards Real-Time Human-AI Reliance Assessment,-1.0,-1.0,-1,Poster,True
22,42,"Michaela Benk, Sophie Kerstan and Andrea Ferrario",You haven't changed a bit! Initial Findings from a Bibliometric Analysis of Two Decades of Empirical Trust in AI Research,-1.0,-1.0,-1,Poster,True
23,4,"Charles Wan, Rodrigo Belo, Leid Zejnilovic and Susana Lavado",The Duet of Representations and How Explanations Exacerbate It,-1.0,-1.0,-1,Poster,True
24,26,Sara Salimzadeh and Ujwal Gadiraju,Simplicity is Complexity Resolved: Considering Task Complexity in Empirical HC(X)AI Studies,-1.0,-1.0,-1,Poster,True
25,41,"Kazuhiko Momose, Troy Weekes, Thomas Eskridge and Daniel Kidwell",Trust and Reliance in Compositional Control Teams,-1.0,-1.0,-1,Poster,True
26,45,"Navita Goyal, Eleftheria Briakou, Marine Carpuat and Hal Daumé III",Background Explanations Reduce User's Over-reliance on AI: A Case Study on Multi-Hop Question Answering,-1.0,-1.0,-1,Poster,True
27,12,"Caitlin Lancaster, Heba Aly, Subhasree Sengupta and Nathan McNeese",Responsible Human-AI Teaming: Interface Designs to Promote Bias Awareness in Human-AI Fact-checking Teams,-1.0,-1.0,-1,Poster,True
